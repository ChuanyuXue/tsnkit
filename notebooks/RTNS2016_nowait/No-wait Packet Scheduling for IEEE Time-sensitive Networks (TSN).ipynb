{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a474c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import tracemalloc\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99a6b340",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracemalloc.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d708ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "macrotick = 100\n",
    "sync_error = 0\n",
    "time_out = 4 * 60 * 60\n",
    "\n",
    "NUM_FLOW = 500\n",
    "DATA_NAME = \"auto0\"\n",
    "TOPO_NAME = \"4\"\n",
    "\n",
    "task = pd.read_csv(\"../../data/utilization/utilization_5_5.csv\")\n",
    "network = pd.read_csv(\"../../data/utilization/utilization_topology.csv\")\n",
    "\n",
    "# task = pd.read_csv(\"../../dac_data/%s.csv\"%DATA_NAME)[:NUM_FLOW]\n",
    "# network = pd.read_csv(\"../../dac_data/%s_topology.csv\"%TOPO_NAME)\n",
    "for col in ['size','period','deadline','jitter']:\n",
    "    task[col] = np.ceil(task[col] / macrotick).astype(int)\n",
    "for col in ['t_proc','t_prop']:\n",
    "    network[col] = np.ceil(network[col] / macrotick).astype(int)\n",
    "    \n",
    "nodes = list(network['link'].apply(lambda x:eval(x)[0])) + \\\n",
    "    list(network['link'].apply(lambda x:eval(x)[1]))\n",
    "NODE_SET = list(set(nodes))\n",
    "ES_set = [x for x in NODE_SET if nodes.count(x) == 2]\n",
    "SW_set = list(set(NODE_SET) - set(ES_set))\n",
    "LCM = np.lcm.reduce(task['period'])\n",
    "net = np.zeros(shape = (max(NODE_SET) + 1, max(NODE_SET) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7730825-4d62-427a-8328-9a35e11b9d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis method assume that traffics are all the same period.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This method assume that traffics are all the same period.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0efc12",
   "metadata": {},
   "source": [
    "## 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df5d9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "M = int(1e16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b18cba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "m = gp.Model(\"RTNS2016-nowait\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc4537",
   "metadata": {},
   "source": [
    "Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f91ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_var = {}\n",
    "\n",
    "for _, row in network.iterrows():\n",
    "    net_var.setdefault(eval(row['link'])[0], {})\n",
    "    net_var[eval(row['link'])[0]]['dproc'] = np.ceil(row['t_proc'])\n",
    "    net[eval(row['link'])[0], eval(row['link'])[1]] = 1\n",
    "\n",
    "## Create mapping from Link to index\n",
    "link_to_index = {}\n",
    "index_to_link = {}\n",
    "\n",
    "counter = 0\n",
    "for _, row in network.iterrows():\n",
    "    link = row['link']\n",
    "    link_to_index[link] = counter\n",
    "    index_to_link[counter] = link\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126e038",
   "metadata": {},
   "source": [
    "Task model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b3690678",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_var = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31288058",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shortest path\n",
    "def bfs_paths(graph, start, goal):\n",
    "    queue = [(start, [start])]\n",
    "    while queue:\n",
    "        (vertex, path) = queue.pop(0)\n",
    "        for _next in set(np.reshape(np.argwhere(graph[vertex] > 0),  -1)) - set(path):\n",
    "            if _next == goal:\n",
    "                yield path + [_next]\n",
    "            else:\n",
    "                queue.append((_next, path + [_next]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8398a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_attr = {}\n",
    "graph = nx.from_numpy_array(net)\n",
    "## Assume task is strictly periodic\n",
    "for i, row in task.iterrows():\n",
    "    task.loc[i,'route'] = str(nx.shortest_path(graph, row['src'], eval(row['dst'])[0]))\n",
    "    task_var.setdefault(i, {})\n",
    "    route = eval(task.loc[i, 'route'])\n",
    "    task_attr.setdefault(i, {})\n",
    "    task_attr[i]['route'] = route\n",
    "    for _i, a in enumerate(route[:-1]):\n",
    "        link = str((a, route[_i + 1]))\n",
    "        task_var[i].setdefault(link, {})\n",
    "        task_var[i][link]['dtrans'] = np.ceil(row['size'] * 8)\n",
    "        if _i == 0:\n",
    "            ## This one must not cantains processing delay\n",
    "            task_var[i][link]['D'] = task_var[i][link]['dtrans']\n",
    "        else:\n",
    "            task_var[i][link]['D'] = task_var[i][str((route[_i - 1], a))]['D'] \\\n",
    "            + net_var[eval(link)[0]]['dproc'] + task_var[i][link]['dtrans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c053615",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = m.addMVar(shape=(len(task)), vtype=GRB.INTEGER , name=\"release\")\n",
    "for i in range(len(task)):\n",
    "    route = eval(task.loc[i, 'route'])\n",
    "    first_link = str((route[0], route[1]))\n",
    "    m.addConstr(0 <= t[i])\n",
    "    m.addConstr(t[i] <= task.loc[i]['period'] - task_var[i][first_link]['dtrans'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63185d5",
   "metadata": {},
   "source": [
    "## 2. Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53010b27",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\min C_{m a x} & \\\\\n",
    "\\text { subject to } & \\\\\n",
    "\\forall\\left\\{O_{i, k}, O_{j, l}\\right\\} \\in K: & \\\\\n",
    "t_{j}-t_{i}-D_{i, k}+D_{j, l-1}+d^{\\text {prop }}+d^{\\text {proc }} & \\leq c x_{i, k, j, l} \\\\\n",
    "\\forall\\left\\{O_{i, k}, O_{j, l}\\right\\} \\in K: & \\\\\n",
    "t_{i}-t_{j}-D_{j, l}+D_{i, k-1}+d^{p r o p}+d^{\\text {proc }} & \\leq c\\left(1-x_{i, k, j, l}\\right)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6e8ec2f-feea-4b33-8b8e-80bff4abbdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nProcessing delay shouldn't be counted in the frame overlap constraint, \\nsince all we need to do is make sure there isn't a collision between window openning statuses.\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Processing delay shouldn't be counted in the frame overlap constraint, \n",
    "since all we need to do is make sure there isn't a collision between window openning statuses.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "356d5e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:00<00:00, 1029.62it/s]\n"
     ]
    }
   ],
   "source": [
    "## i < j REQUIRED TO BE MERGED INTO GITREPO\n",
    "for i, j in tqdm([(i,j) for i in task_var for j in task_var if i < j]):\n",
    "    i_r, j_r = task_attr[i]['route'], task_attr[j]['route']\n",
    "    i_t, j_t = task.loc[i].period, task.loc[j].period\n",
    "    lcm = np.lcm(i_t, j_t)\n",
    "    for k, l in [(k, l) for k in range(len(i_r) - 1) for l in range(len(j_r) - 1)]:\n",
    "        if str((i_r[k], i_r[k+1])) == str((j_r[l], j_r[l+1])):\n",
    "            link = str((i_r[k], i_r[k+1]))\n",
    "            for a, b in [\n",
    "                            (a, b) for a in range(0, int(lcm / task.loc[i].period))\n",
    "                                for b in range(0, int(lcm / task.loc[j].period))\n",
    "                        ]:\n",
    "                temp = m.addVar(vtype=GRB.BINARY,\n",
    "                                    name=\"%d%d%d%d%s\" % (i, j, a, b, link))\n",
    "                m.addConstr(\n",
    "                    (t[j] + b * j_t) - (t[i] + a * i_t) - task_var[i][link]['D'] + task_var[i][link]['dtrans']\n",
    "                    + task_var[j][link]['D'] <= M * temp\n",
    "                )\n",
    "                m.addConstr(\n",
    "                    (t[i] + a * i_t) - (t[j] + b * j_t) - task_var[j][link]['D'] + task_var[j][link]['dtrans']\n",
    "                    + task_var[i][link]['D'] <= M * (1 - temp)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46a76f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.5.2 build v9.5.2rc0 (linux64)\n",
      "Thread count: 8 physical cores, 16 logical processors, using up to 16 threads\n",
      "Optimize a model with 104 rows, 52 columns and 268 nonzeros\n",
      "Model fingerprint: 0xd78e65c1\n",
      "Variable types: 0 continuous, 52 integer (41 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 1e+16]\n",
      "  Objective range  [0e+00, 0e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [8e+00, 1e+16]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "Warning: Model contains large rhs\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "\n",
      "MIP start from previous solve did not produce a new incumbent solution\n",
      "\n",
      "Presolve removed 22 rows and 0 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 82 rows, 52 columns, 246 nonzeros\n",
      "Variable types: 0 continuous, 52 integer (41 binary)\n",
      "Found heuristic solution: objective 0.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.01 seconds (0.00 work units)\n",
      "Thread count was 16 (of 16 available processors)\n",
      "\n",
      "Solution count 1: 0 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 0.000000000000e+00, best bound 0.000000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    m.optimize()\n",
    "except gp.GurobiError as E:\n",
    "    print(\"Optimize failed\", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a441a-9894-4ce1-b9d0-e987c23107c3",
   "metadata": {},
   "source": [
    "## Output Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5210e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCL = []\n",
    "for i in task_var:\n",
    "    for e in task_var[i]:\n",
    "        start = t[i].x + task_var[i][e]['D'] - task_var[i][e]['dtrans']\n",
    "        end = start + task_var[i][e]['dtrans']\n",
    "        queue = 0\n",
    "        tt = task.loc[i, 'period']\n",
    "        for k in range(int(LCM / tt)):\n",
    "            GCL.append(\n",
    "                [e, queue, (start + k * tt) * macrotick, (end + k * tt) * macrotick, LCM * macrotick]\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f5931641-08ca-457b-80ec-dff9622afae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Offset\n",
    "OFFSET = []\n",
    "for i in task_var:\n",
    "    offset = t[i].x\n",
    "    OFFSET.append(\n",
    "        [i, 0, (task.loc[i,'period'] - offset) * macrotick]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "4f1bd401-af49-4c22-97b8-9a6a7b0c79fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTE = []\n",
    "for i, row in task.iterrows():\n",
    "    route = task_attr[i]['route']\n",
    "    for h, v in enumerate(route[:-1]):\n",
    "        ROUTE.append(\n",
    "            [i, (v, route[h + 1])]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d981d134-8d11-4915-8dc7-30872681ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUEUE = []\n",
    "for i in task_var:\n",
    "    for e in task_var[i]:\n",
    "        QUEUE.append([i, 0, eval(e), 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1a5fe9df-da2f-4901-b8ed-abe393f25548",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCL = pd.DataFrame(GCL)\n",
    "GCL.columns = [\"link\", \"queue\", \"start\", \"end\", \"cycle\"]\n",
    "GCL.to_csv(\"RTNS2016_nowait-%s-%d-%s-GCL.csv\"%(DATA_NAME,NUM_FLOW,TOPO_NAME), index=False)\n",
    "\n",
    "OFFSET = pd.DataFrame(OFFSET)\n",
    "OFFSET.columns = ['id', 'ins_id', 'offset']\n",
    "OFFSET.to_csv(\"RTNS2016_nowait-%s-%d-%s-OFFSET.csv\"%(DATA_NAME,NUM_FLOW,TOPO_NAME), index=False)\n",
    "\n",
    "ROUTE = pd.DataFrame(ROUTE)\n",
    "ROUTE.columns = ['id', 'link']\n",
    "ROUTE.to_csv(\"RTNS2016_nowait-%s-%d-%s-ROUTE.csv\"%(DATA_NAME,NUM_FLOW,TOPO_NAME), index=False)\n",
    "\n",
    "QUEUE = pd.DataFrame(QUEUE)\n",
    "QUEUE.columns = ['id','ins_id','link','queue']\n",
    "QUEUE.to_csv(\"RTNS2016_nowait-%s-%d-%s-QUEUE.csv\"%(DATA_NAME,NUM_FLOW,TOPO_NAME), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "34060ed1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8641791343688965"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "776de08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.733712196350098\n"
     ]
    }
   ],
   "source": [
    "print(tracemalloc.get_traced_memory()[1] / 1024 / 1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2ed828a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mCannot execute code, session has been disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "tracemalloc.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
