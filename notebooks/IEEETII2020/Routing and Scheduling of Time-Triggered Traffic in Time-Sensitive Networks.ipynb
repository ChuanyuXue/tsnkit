{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a474c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "from sklearn.cluster import SpectralClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "265a790d",
   "metadata": {},
   "outputs": [],
   "source": [
    "macrotick = 100\n",
    "sync_error = 0\n",
    "time_out = 4 * 60 * 60\n",
    "\n",
    "NUM_FLOW = 40\n",
    "DATA_NAME = \"harmonic9\"\n",
    "TOPO_NAME = \"0\"\n",
    "\n",
    "task = pd.read_csv(\"../../dac_data/%s.csv\"%DATA_NAME)[:NUM_FLOW]\n",
    "network = pd.read_csv(\"../../dac_data/%s_topology.csv\"%TOPO_NAME)\n",
    "for col in ['size','period','deadline','jitter']:\n",
    "    task[col] = np.ceil(task[col] / macrotick).astype(int)\n",
    "for col in ['t_proc','t_prop']:\n",
    "    network[col] = np.ceil(network[col] / macrotick).astype(int)\n",
    "    \n",
    "nodes = list(network['link'].apply(lambda x:eval(x)[0])) + \\\n",
    "    list(network['link'].apply(lambda x:eval(x)[1]))\n",
    "NODE_SET = list(set(nodes))\n",
    "ES_set = [x for x in NODE_SET if nodes.count(x) == 2]\n",
    "SW_set = list(set(NODE_SET) - set(ES_set))\n",
    "LCM = np.lcm.reduce(task['period'])\n",
    "net = np.zeros(shape = (max(NODE_SET) + 1, max(NODE_SET) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0efc12",
   "metadata": {},
   "source": [
    "## 1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b18cba53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "m = gp.Model(\"IEEETII2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb8bdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unicast\n",
    "\n",
    "M = int(1e16)\n",
    "NG = 5\n",
    "ITRN = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbc4537",
   "metadata": {},
   "source": [
    "Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f91ae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_var = {}\n",
    "\n",
    "for _, row in network.iterrows():\n",
    "    net_var.setdefault(eval(row['link'])[0], {})\n",
    "    net_var[eval(row['link'])[0]]['tproc'] = np.ceil(row['t_proc'])\n",
    "    net[eval(row['link'])[0], eval(row['link'])[1]] = 1\n",
    "\n",
    "## Create mapping from Link to index\n",
    "link_to_index = {}\n",
    "index_to_link = {}\n",
    "\n",
    "counter = 0\n",
    "for _, row in network.iterrows():\n",
    "    link = row['link']\n",
    "    link_to_index[link] = counter\n",
    "    index_to_link[counter] = link\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4126e038",
   "metadata": {},
   "source": [
    "Task model\n",
    "\n",
    "$$s_m^r \\equiv\\left(s r_m, d_m, p_m, s i_m, \\mathscr{P}_m^r\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31288058",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shortest path\n",
    "def bfs_paths(graph, start, goal):\n",
    "    queue = [(start, [start])]\n",
    "    while queue:\n",
    "        (vertex, path) = queue.pop(0)\n",
    "        for _next in set(np.reshape(np.argwhere(graph[vertex] > 0),  -1)) - set(path):\n",
    "            if _next == goal:\n",
    "                yield path + [_next]\n",
    "            else:\n",
    "                queue.append((_next, path + [_next]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8398a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_attr = {}\n",
    "task_var = {}\n",
    "\n",
    "## Assume task is strictly periodic\n",
    "for i, row in task.iterrows():\n",
    "    task_var.setdefault(i, {})\n",
    "    task_attr.setdefault(i, {})\n",
    "    task_attr[i]['sr'] = row['src']\n",
    "    task_attr[i]['d'] = row['dst']\n",
    "    task_attr[i]['p'] = row['period']\n",
    "    task_attr[i]['si'] = row['size']\n",
    "    task_attr[i]['dl'] = row['deadline']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c787737-6092-4c83-b8b5-f43e75b97d95",
   "metadata": {},
   "source": [
    "## 2. Graph based stream partitioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf94c52c-6883-46f2-b85d-48f974a4ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all_paths(graph, start, end, path=[]):\n",
    "    path = path + [start]\n",
    "    if start == end:\n",
    "        return [path]\n",
    "    paths = []\n",
    "    for node in set(np.reshape(np.argwhere(graph[start] > 0),  -1)):\n",
    "        if node not in path:\n",
    "            newpaths = find_all_paths(graph, node, end, path)\n",
    "            for newpath in newpaths:\n",
    "                paths.append(newpath)\n",
    "    return paths     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d25ca60-2c55-4bae-9114-f475fabb388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {}\n",
    "for i in task_attr:\n",
    "    paths[i] = find_all_paths(net, task_attr[i]['sr'],eval(task_attr[i]['d'])[0])\n",
    "    for k in range(len(paths[i])):\n",
    "        paths[i][k] = list({x: int(eval(str(paths[i][k]))[h+1]) for h, x in enumerate(eval(str(paths[i][k]))[:-1])}.items())\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fbf4d6e-b4a7-40b8-8771-002333e51951",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_net = np.zeros(shape = (len(task), len(task)))\n",
    "for i in task_attr:\n",
    "    for j in task_attr:\n",
    "        if i < j:\n",
    "            doc_net[i][j] = doc_net[j][i] = len(set([x for y in paths[i] for x in y]) & set([x for y in paths[j] for x in y])) * \\\n",
    "            task_attr[i]['si'] * task_attr[j]['si'] / task_attr[i]['p'] * task_attr[j]['p'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c77cb1e1-cd53-47be-89b6-bfbc724acdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = SpectralClustering(n_clusters = NG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d0736d-ef95-405c-a943-c990b9f872ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chuanyu/.local/lib/python3.8/site-packages/sklearn/cluster/_spectral.py:658: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\n",
      "/home/chuanyu/.local/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:259: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "task_group = cluster.fit_predict(doc_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c9a0bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_group = [x for y in [[i] * int(np.ceil(len(task) / NG)) for i in range(NG)] for x in y]\n",
    "# task_group = [0] * len(task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ebf3e8-ac95-4d22-a5f1-79d391f9e028",
   "metadata": {},
   "source": [
    "## 3. DAMR Procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "10904111-a8cf-4b2e-86f4-4a2a32ba2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = [0 for i in task_attr]\n",
    "costs = [sum([ \n",
    "    len(set(paths[i][opt[i]]) & set(paths[j][opt[j]])) * \\\n",
    "            task_attr[i]['si'] * task_attr[j]['si'] / task_attr[i]['p'] * task_attr[j]['p'] \n",
    "     for j in task_attr if i != j]) for i in task_attr]\n",
    "\n",
    "for it in range(ITRN):\n",
    "    i = np.argmax(costs)\n",
    "    best = costs[i]\n",
    "    m_star = opt[i]\n",
    "    for m in range(len(paths[i])):\n",
    "        if m != opt[i]:\n",
    "            cost = sum([len(set(paths[i][m]) & set(paths[j][opt[j]])) * \\\n",
    "            task_attr[i]['si'] * task_attr[j]['si'] / task_attr[i]['p'] * task_attr[j]['p'] for j in task_attr])\n",
    "            if cost < best:\n",
    "                best = cost\n",
    "                m_star = m\n",
    "    opt[i] = m_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "e528696c-8308-411f-ba77-f7a191221a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in task_attr:\n",
    "    task_attr[i]['r'] = paths[i][opt[i]]\n",
    "\n",
    "# for i in task_attr:\n",
    "#     path = eval(str(next(bfs_paths(net, int(row['src']), eval(row['dst'])[0]))))\n",
    "#     task_attr[i]['r'] = [(x, path[i + 1]) for i,x in enumerate(path[:-1])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "3b2dbdef-4edf-4083-80c3-a43cfe5411d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assume task is strictly periodic\n",
    "for i, row in task.iterrows():\n",
    "    task_var.setdefault(i, {})\n",
    "    route = task_attr[i]['r']\n",
    "    for _i, link in enumerate(route):\n",
    "        task_var[i].setdefault(link, {})\n",
    "        task_var[i][link]['dtrans'] = row['size'] * 8\n",
    "        if _i == 0:## This one must not cantains processing delay\n",
    "            \n",
    "            task_var[i][link]['D'] = task_var[i][link]['dtrans']\n",
    "        else:\n",
    "            task_var[i][link]['D'] = task_var[i][route[_i - 1]]['D'] + net_var[link[0]]['tproc'] + task_var[i][link]['dtrans']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63185d5",
   "metadata": {},
   "source": [
    "## 4. Constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53010b27",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\min C_{m a x} & \\\\\n",
    "\\text { subject to } & \\\\\n",
    "\\forall\\left\\{O_{i, k}, O_{j, l}\\right\\} \\in K: & \\\\\n",
    "t_{j}-t_{i}-D_{i, k}+D_{j, l-1}+d^{\\text {prop }}+d^{\\text {proc }} & \\leq c x_{i, k, j, l} \\\\\n",
    "\\forall\\left\\{O_{i, k}, O_{j, l}\\right\\} \\in K: & \\\\\n",
    "t_{i}-t_{j}-D_{j, l}+D_{i, k-1}+d^{p r o p}+d^{\\text {proc }} & \\leq c\\left(1-x_{i, k, j, l}\\right)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "356d5e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = [None for i in task_var]\n",
    "\n",
    "for epoch in range(NG):\n",
    "    m = gp.Model(\"IEEEII2022_%d\"%epoch)\n",
    "    m.Params.LogToConsole = 0\n",
    "    t = m.addMVar(shape=(len(task)), vtype=GRB.INTEGER , name=\"release\")\n",
    "    for i in [i for i in task_var if task_group[i] == epoch]:\n",
    "        end_link = task_attr[i]['r'][-1]\n",
    "        m.addConstr(0 <= t[i])\n",
    "        m.addConstr(t[i] <= task.loc[i]['period'] - task_var[i][end_link]['D'])\n",
    "    ## Add constraint within task subgroup\n",
    "    for i, j in [(i,j) for i in task_var for j in task_var if task_group[i] == epoch]:\n",
    "        ir, jr = task_attr[i]['r'], task_attr[j]['r']\n",
    "        lcm = np.lcm(task.loc[i].period, task.loc[j].period)\n",
    "        for k, l in [(k, l) for k in range(len(ir)) for l in range(len(jr))]:\n",
    "            if i != j and ir[k] == jr[l] and task_group[j] == epoch:\n",
    "                for a, b in [(a,b) for a in range(0, int(lcm / task.loc[i].period)) for b in range(0, int(lcm / task.loc[j].period))]:\n",
    "                    temp = m.addVar(vtype=GRB.BINARY, name = \"%d%d%d%d\"%(i,j,k,l))\n",
    "                    m.addConstr(\n",
    "                        (t[j] + b * task.loc[j].period) - (t[i] + a * task.loc[i].period) - task_var[i][ir[k]]['D'] + task_var[i][ir[k]]['dtrans'] \n",
    "                        + task_var[j][jr[l]]['D'] <= M * temp\n",
    "                    )\n",
    "                    m.addConstr(\n",
    "                        (t[i] + a * task.loc[i].period) - (t[j] + b * task.loc[j].period) - task_var[j][jr[l]]['D'] + task_var[j][jr[l]]['dtrans'] \n",
    "                        + task_var[i][ir[k]]['D'] <= M * (1 - temp)\n",
    "                    )\n",
    "            if i != j and ir[k] == jr[l] and task_group[j] < epoch:\n",
    "                for a, b in [(a,b) for a in range(0, int(lcm / task.loc[i].period)) for b in range(0, int(lcm / task.loc[j].period))]:\n",
    "                    temp = m.addVar(vtype=GRB.BINARY, name = \"%d%d%d%d\"%(i,j,k,l))\n",
    "                    m.addConstr(\n",
    "                        (solutions[j] + b * task.loc[j].period) - (t[i] + a * task.loc[i].period) - task_var[i][ir[k]]['D'] + task_var[i][ir[k]]['dtrans'] \n",
    "                        + task_var[j][jr[l]]['D'] <= M * temp\n",
    "                    )\n",
    "                    m.addConstr(\n",
    "                        (t[i] + a * task.loc[i].period) - (solutions[j] + b * task.loc[j].period) - task_var[j][jr[l]]['D'] + task_var[j][jr[l]]['dtrans'] \n",
    "                        + task_var[i][ir[k]]['D'] <= M * (1 - temp)\n",
    "                    )\n",
    "    m.optimize()\n",
    "    for i in [i for i in task_var if task_group[i] == epoch]:\n",
    "        solutions[i] = t[i].x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13a441a-9894-4ce1-b9d0-e987c23107c3",
   "metadata": {},
   "source": [
    "## Output Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210e993",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCL = []\n",
    "for i in task_var:\n",
    "    path = task_attr[i]['r']\n",
    "    for e in path:\n",
    "        start = solutions[i] + task_var[i][e]['D'] - task_var[i][e]['dtrans']\n",
    "        end = start + task_var[i][e]['dtrans']\n",
    "        queue = 0\n",
    "        tt = task.loc[i, 'period']\n",
    "        for k in range(int(LCM / tt)):\n",
    "            GCL.append(\n",
    "                [e, queue, int(start + k * tt) * macrotick, int(end + k * tt) * macrotick, LCM * macrotick]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad02768-8f03-4921-865e-bdf217a6f333",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Offset\n",
    "OFFSET = []\n",
    "for i in task_var:\n",
    "    offset = solutions[i]\n",
    "    OFFSET.append(\n",
    "        [i, 0, (task.loc[i,'period'] - offset) * macrotick]\n",
    "    )    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582a0c7e-abe2-453b-9d55-a6813571e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROUTE = []\n",
    "for i in task_attr:\n",
    "    for link in task_attr[i]['r']:\n",
    "        ROUTE.append([i, link])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427aa5f9-09e1-4790-a3bb-c81c5fdfa6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUEUE = []\n",
    "for i in task_attr:\n",
    "    for e in task_attr[i]['r']:\n",
    "        QUEUE.append([i, 0, e, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afbd97-a22f-4d2d-9f70-64e32937002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCL = pd.DataFrame(GCL)\n",
    "GCL.columns = [\"link\", \"queue\", \"start\", \"end\", \"cycle\"]\n",
    "GCL.to_csv(\"IEEETII2020-%s-%d-%s-GCL.csv\"%(DATA_NAME,NUM_FLOW,TOPO_NAME), index=False)\n",
    "\n",
    "OFFSET = pd.DataFrame(OFFSET)\n",
    "OFFSET.columns = ['id', 'ins_id', 'offset']\n",
    "OFFSET.to_csv(\"IEEETII2020-%s-%d-%s-OFFSET.csv\"%(DATA_NAME,NUM_FLOW,TOPO_NAME), index=False)\n",
    "\n",
    "ROUTE = pd.DataFrame(ROUTE)\n",
    "ROUTE.columns = ['id', 'link']\n",
    "ROUTE.to_csv(\"IEEETII2020-%s-%d-%s-ROUTE.csv\"%(DATA_NAME,NUM_FLOW,TOPO_NAME), index=False)\n",
    "\n",
    "QUEUE = pd.DataFrame(QUEUE)\n",
    "QUEUE.columns = ['id','ins_id','link','queue']\n",
    "QUEUE.to_csv(\"IEEETII2020-%s-%d-%s-QUEUE.csv\"%(DATA_NAME,NUM_FLOW,TOPO_NAME), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
