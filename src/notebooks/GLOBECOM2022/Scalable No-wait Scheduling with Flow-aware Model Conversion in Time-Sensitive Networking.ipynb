{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ 16,  52,  63,  66,  90,  99, 123, 143, 179, 191, 196]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "macrotick = 100\n",
    "sync_error = 0\n",
    "time_out = 4 * 60 * 60\n",
    "ins = 10\n",
    "task = pd.read_csv(f\"../../data/utilization/utilization_40_{ins}_task.csv\")\n",
    "network = pd.read_csv(f\"../../data/utilization/utilization_40_{ins}_topo.csv\")\n",
    "\n",
    "for col in ['size','period','deadline','jitter']:\n",
    "    task[col] = np.ceil(task[col] / macrotick).astype(int)\n",
    "for col in ['t_proc','t_prop']:\n",
    "    network[col] = np.ceil(network[col] / macrotick).astype(int)\n",
    "    \n",
    "nodes = list(network['link'].apply(lambda x:eval(x)[0])) + \\\n",
    "    list(network['link'].apply(lambda x:eval(x)[1]))\n",
    "NODE_SET = list(set(nodes))\n",
    "ES_set = [x for x in NODE_SET if nodes.count(x) == 2]\n",
    "SW_set = list(set(NODE_SET) - set(ES_set))\n",
    "LCM = np.lcm.reduce(task['period'])\n",
    "net = np.zeros(shape = (max(NODE_SET) + 1, max(NODE_SET) + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shortest path\n",
    "def bfs_paths(graph, start, goal):\n",
    "    queue = [(start, [start])]\n",
    "    while queue:\n",
    "        (vertex, path) = queue.pop(0)\n",
    "        for _next in set(np.reshape(np.argwhere(graph[vertex] > 0),  -1)) - set(path):\n",
    "            if _next == goal:\n",
    "                yield path + [_next]\n",
    "            else:\n",
    "                queue.append((_next, path + [_next]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_var = {}\n",
    "\n",
    "for _, row in network.iterrows():\n",
    "    net_var.setdefault(eval(row['link'])[0], {})\n",
    "    net_var[eval(row['link'])[0]]['dproc'] = np.ceil(row['t_proc'])\n",
    "    net[eval(row['link'])[0], eval(row['link'])[1]] = 1\n",
    "\n",
    "## Create mapping from Link to index\n",
    "link_to_index = {}\n",
    "index_to_link = {}\n",
    "\n",
    "counter = 0\n",
    "for _, row in network.iterrows():\n",
    "    link = row['link']\n",
    "    link_to_index[link] = counter\n",
    "    index_to_link[counter] = link\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_attr = {}\n",
    "task_var = {}\n",
    "graph = nx.from_numpy_array(net)\n",
    "## Assume task is strictly periodic\n",
    "for i, row in task.iterrows():\n",
    "    task.loc[i,'route'] = str(nx.shortest_path(graph, row['src'], eval(row['dst'])[0]))\n",
    "    task_var.setdefault(i, {})\n",
    "    route = eval(task.loc[i, 'route'])\n",
    "    task_attr.setdefault(i, {})\n",
    "    task_attr[i]['route'] = route\n",
    "    task_attr[i]['p'] = row['period']\n",
    "    task_attr[i]['d'] = row['deadline']\n",
    "    for _i, a in enumerate(route[:-1]):\n",
    "        link = str((a, route[_i + 1]))\n",
    "        task_var[i].setdefault(link, {})\n",
    "        task_var[i][link]['dtrans'] = np.ceil(row['size'] * 8)\n",
    "        if _i == 0:\n",
    "            ## This one must not cantains processing delay\n",
    "            task_var[i][link]['D'] = task_var[i][link]['dtrans']\n",
    "        else:\n",
    "            task_var[i][link]['D'] = task_var[i][str((route[_i - 1], a))]['D'] \\\n",
    "            + net_var[eval(link)[0]]['dproc'] + task_var[i][link]['dtrans']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod(dividend, divisor):\n",
    "    result = dividend % divisor\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collision_free_interval(i, j, link):\n",
    "    global config_hash\n",
    "    offset_j = config_hash[j]\n",
    "    tau = offset_j + (task_var[j][link]['D'] - task_var[j][link]['dtrans'])\\\n",
    "        - (task_var[i][link]['D'] - task_var[i][link]['dtrans'])\n",
    "\n",
    "    phi_interval = (\n",
    "        tau - task_var[i][link]['dtrans'],\n",
    "        tau + task_var[j][link]['dtrans']\n",
    "    )\n",
    "    return phi_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_set = set()\n",
    "config_hash = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "a = 100\n",
    "\n",
    "if a > 0:\n",
    "    print('a')\n",
    "elif a > 2:\n",
    "    print('b')\n",
    "else:\n",
    "    print('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/chuanyu/Code/Time-Sensitive-Network-Benchmark/notebooks/GLOBECOM2022/Scalable No-wait Scheduling with Flow-aware Model Conversion in Time-Sensitive Networking.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chuanyu/Code/Time-Sensitive-Network-Benchmark/notebooks/GLOBECOM2022/Scalable%20No-wait%20Scheduling%20with%20Flow-aware%20Model%20Conversion%20in%20Time-Sensitive%20Networking.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m## Main algorithm\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chuanyu/Code/Time-Sensitive-Network-Benchmark/notebooks/GLOBECOM2022/Scalable%20No-wait%20Scheduling%20with%20Flow-aware%20Model%20Conversion%20in%20Time-Sensitive%20Networking.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m epi \u001b[39min\u001b[39;00m tqdm(task_attr):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chuanyu/Code/Time-Sensitive-Network-Benchmark/notebooks/GLOBECOM2022/Scalable%20No-wait%20Scheduling%20with%20Flow-aware%20Model%20Conversion%20in%20Time-Sensitive%20Networking.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     divider_interval_set \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chuanyu/Code/Time-Sensitive-Network-Benchmark/notebooks/GLOBECOM2022/Scalable%20No-wait%20Scheduling%20with%20Flow-aware%20Model%20Conversion%20in%20Time-Sensitive%20Networking.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m## Collect all the collision intervals\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "## Main algorithm\n",
    "for epi in tqdm(task_attr):\n",
    "    divider_interval_set = []\n",
    "    ## Collect all the collision intervals\n",
    "    for i in scheduled_set:\n",
    "        for link in [link_i for link_i in task_var[i] for link_epi in task_var[epi] if link_i == link_epi]:\n",
    "            divider = np.gcd(task_attr[i]['p'], task_attr[epi]['p'])\n",
    "            interval = collision_free_interval(epi, i, link)\n",
    "            interval_regulated = (mod(interval[0], divider), mod(interval[1], divider))\n",
    "            if interval_regulated[0] >= interval_regulated[1]:\n",
    "                divider_interval_set.append((divider, (-1, interval_regulated[1]), (i,link)))\n",
    "                divider_interval_set.append((divider, (interval_regulated[0], divider), (i,link)))                \n",
    "            else:\n",
    "                divider_interval_set.append((divider, interval_regulated, (i,link)))\n",
    "    end_link = str((task_attr[epi]['route'][-2] ,task_attr[epi]['route'][-1]))\n",
    "    offset_upper_bound = task_attr[epi]['p'] - task_var[epi][end_link]['D']\n",
    "    injection_time = 0\n",
    "    trial_counter = 0\n",
    "    divider_interval_set = sorted(divider_interval_set, key=lambda x:x[1][1], reverse=False)\n",
    "    cyclic_index = 0\n",
    "    \n",
    "    while trial_counter < len(divider_interval_set):\n",
    "        divider, interval, _ = divider_interval_set[cyclic_index]\n",
    "        assert interval[0] < interval[1], divider_interval_set\n",
    "        regulated_offset = mod(injection_time, divider)\n",
    "        if regulated_offset > interval[0] and regulated_offset < interval[1]:\n",
    "            if interval[1] > injection_time:\n",
    "                injection_time = interval[1]\n",
    "            else:\n",
    "                injection_time += interval[1] - interval[0]\n",
    "#             print(injection_time)\n",
    "            trial_counter = 1\n",
    "            if injection_time > offset_upper_bound:\n",
    "                raise Exception(f\"Flow {epi} cannot be scheduled\")\n",
    "                break\n",
    "        else:\n",
    "            trial_counter += 1\n",
    "        cyclic_index += 1\n",
    "        if cyclic_index == len(divider_interval_set):\n",
    "            cyclic_index = 0\n",
    "    scheduled_set.add(epi)\n",
    "    config_hash[epi] = injection_time\n",
    "#     print(f\"Flow {epi} injection time {injection_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check if the schedule is collision free\n",
    "GCL = {}\n",
    "for epi in task_var:\n",
    "    for link in task_var[epi]:\n",
    "        GCL.setdefault(link, [])\n",
    "        GCL[link].append((config_hash[epi] + task_var[epi][link]['D'] - task_var[epi][link]['dtrans'], \n",
    "                              config_hash[epi] + task_var[epi][link]['D'], 0, epi))\n",
    "for link in GCL:\n",
    "    GCL[link] = sorted(GCL[link], key=lambda x: x[0], reverse=False)\n",
    "    temp = GCL[link]\n",
    "    for i, row in enumerate(temp[:-1]):\n",
    "        assert row[1] <= temp[i + 1][0], f\"Overlap {link}\\n Entry1 {row}\\n Entry2 {temp[i + 1]}\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
